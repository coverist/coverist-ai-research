data:
  book_dataset: ../../resources/kyobobook-dataset.jsonl
  image_dataset: ../../resources/kyobobook-quantized.csv
  text_max_length: 64
  validation_ratio: 0.01

model:
  vqgan: vqgan-decoder.pth
  encoder: klue/roberta-large
  decoder:
    is_decoder: true
    add_cross_attention: true
    vocab_size: 16385
    hidden_size: 512
    num_hidden_layers: 6
    num_attention_heads: 8
    intermediate_size: 2048
    max_position_embeddings: 577
    layer_norm_eps: 1e-5
    bos_token_id: 16384
    eos_token_id: 16384
  generation:
    max_length: 577
    min_length: 577
    do_sample: true
    temperature: 1.0
    top_k: 0

optim:
  optimizer:
    lr: 6e-5
    betas: [0.9, 0.999]
    eps: 1e-6
    weight_decay: 0.01
  scheduler:
    name: linear
    num_warmup_steps: 10000
    num_training_steps: 500000

train:
  name: dalle-klue-roberta-large
  batch_size: 128
  accumulate_grad_batches: 1
  gradient_clip_val: 1.0
  validation_interval: 1.0
  log_every_n_steps: 10
